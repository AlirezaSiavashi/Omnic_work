{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48f8a4e-faea-4589-b4b7-fbedfafaf19e",
   "metadata": {},
   "source": [
    "# Task 2: Why are the predictions to good (/bad)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527419fe-8e73-4bd4-bde5-28cdcc92a861",
   "metadata": {},
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae778c4-8eaa-4b28-91f9-58004a71f914",
   "metadata": {},
   "source": [
    "> I ran the following code for a binary classification task w/ an SVM in both R (first sample) and Python (second example).\n",
    ">\n",
    "> Given randomly generated data (X) and response (Y), this code performs leave group out cross validation 1000 times. Each entry of Y is therefore the mean of the prediction across CV iterations.\n",
    "> \n",
    "> Computing area under the curve should give ~0.5, since X and Y are completely random. However, this is not what we see. Area under the curve is frequently significantly higher than 0.5. The number of rows of X is very small, which can obviously cause problems.\n",
    ">\n",
    "> Any idea what could be happening here? I know that I can either increase the number of rows of X or decrease the number of columns to mediate the problem, but I am looking for other issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eecb359-6799-4523-9cdd-05187e1230b2",
   "metadata": {},
   "source": [
    "```R\n",
    "Y=as.factor(rep(c(1,2), times=14))\n",
    "X=matrix(runif(length(Y)*100), nrow=length(Y))\n",
    "\n",
    "library(e1071)\n",
    "library(pROC)\n",
    "\n",
    "colnames(X)=1:ncol(X)\n",
    "iter=1000\n",
    "ansMat=matrix(NA,length(Y),iter)\n",
    "for(i in seq(iter)){    \n",
    "    #get train\n",
    "\n",
    "    train=sample(seq(length(Y)),0.5*length(Y))\n",
    "    if(min(table(Y[train]))==0)\n",
    "    next\n",
    "\n",
    "    #test from train\n",
    "    test=seq(length(Y))[-train]\n",
    "\n",
    "    #train model\n",
    "    XX=X[train,]\n",
    "    YY=Y[train]\n",
    "    mod=svm(XX,YY,probability=FALSE)\n",
    "    XXX=X[test,]\n",
    "    predVec=predict(mod,XXX)\n",
    "    RFans=attr(predVec,'decision.values')\n",
    "    ansMat[test,i]=as.numeric(predVec)\n",
    "}\n",
    "\n",
    "ans=rowMeans(ansMat,na.rm=TRUE)\n",
    "\n",
    "r=roc(Y,ans)$auc\n",
    "print(r)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e4617-608b-4749-9ec5-edf15814f5bf",
   "metadata": {},
   "source": [
    "Similarly, when I implement the same thing in Python I get similar results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1f2730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09d266",
   "metadata": {},
   "source": [
    "First of all, I want to normalized the random variables X, to be sure that they are on a similar scale because we are using distance-based algorithm (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dccc7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([1, 2]*14)\n",
    "x = np.random.uniform(size=[len(Y), 100])\n",
    "X_normalized = normalize(x, axis=1)\n",
    "X = X_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687ac5e",
   "metadata": {},
   "source": [
    "now I want to find the best parameters [C and gamma ] for classifing the given dataset with gridcv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "add86b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C' : [1, 10,80 ,100, 1000],\n",
    "        'gamma': ['scale', 1, 0.1,0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf'],\n",
    "    }\n",
    "]\n",
    "kfold = KFold(n_splits=5) \n",
    "svc = SVC(probability=True)\n",
    "optimal_params = GridSearchCV(\n",
    "    SVC(probability=True),\n",
    "    param_grid,\n",
    "    cv = kfold,\n",
    "    scoring = 'roc_auc',\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98171a9",
   "metadata": {},
   "source": [
    "I have use these parameter bellow in my SVC() to solve the problem and enhance the result to the reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8da18f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_parameter for RBF kernel is :\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "optimal_params.fit(X,Y)\n",
    "print('optimal_parameter for RBF kernel is :')\n",
    "print( optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cf44d8d-ca36-4d6b-bafd-78cade069751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([1, 2]*14)\n",
    "X = np.random.uniform(size=[len(Y), 100])\n",
    "n_iter = 1000\n",
    "ansMat = np.full((len(Y), n_iter), np.nan)\n",
    "for i in range(n_iter):\n",
    "    # Get train/test index\n",
    "    train = np.random.choice(range(len(Y)), size=int(0.5*len(Y)), replace=False, p=None)\n",
    "    if len(np.unique(Y)) == 1:\n",
    "        continue\n",
    "    test = np.array([i for i in range(len(Y)) if i not in train])\n",
    "    # train model\n",
    "    mod = SVC(probability=False)\n",
    "    mod.fit(X=X[train, :], y=Y[train])\n",
    "    # predict and collect answer\n",
    "    ansMat[test, i] = mod.predict(X[test, :])\n",
    "ans = np.nanmean(ansMat, axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(Y, ans, pos_label=1)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8302f4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[490 497 505 478 497 504 512 498 512 501 500 491 503 500 517 457 523 516\n",
      " 486 510 513 493 514 486 523 496 486 492]\n",
      "[1.5372549  1.26242545 1.58787879 1.55555556 1.5387674  1.27620968\n",
      " 1.51639344 1.37051793 1.55737705 1.32665331 1.434      1.27897839\n",
      " 1.56740443 1.504      1.69151139 1.2946593  1.41509434 1.46487603\n",
      " 1.58365759 1.51836735 1.45995893 1.30769231 1.68518519 1.28210117\n",
      " 1.67085954 1.43452381 1.54669261 1.31692913]\n",
      "0.9030612244897959\n"
     ]
    }
   ],
   "source": [
    "nan_counts_per_row = np.count_nonzero(np.isnan(ansMat), axis=1)\n",
    "# Print the number of nan values in each row\n",
    "print(nan_counts_per_row)\n",
    "print(ans)\n",
    "fpr, tpr, thresholds = roc_curve(Y, ans, pos_label=1)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504cde2c-c5fd-4bc8-8aba-efb044d31198",
   "metadata": {},
   "source": [
    "## Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc79e824",
   "metadata": {},
   "source": [
    "the problem is that about half of the ansMat is nan due to using half of dataset for training and half for testing in leave group out cross validation, leading the number of nan with signficant diffrences with others row, printed above, which cause this problem. To solve this issue we need to calculate probability estimates for each fold and iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "082f817e-55be-494c-a316-93c4042ed41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5561224489795918\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([1, 2]*14)\n",
    "X = np.random.uniform(size=[len(Y), 100])\n",
    "n_iter = 1000\n",
    "prob_estimates = np.zeros((len(Y), n_iter))\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # Get train/test index\n",
    "    train = np.random.choice(range(len(Y)), size=int(0.5*len(Y)), replace=False, p=None)\n",
    "    if len(np.unique(Y)) ==  1:\n",
    "        continue\n",
    "    test = np.array([i for i in range(len(Y)) if i not in train])\n",
    "    \n",
    "    # Train model with probability estimation enabled\n",
    "    \n",
    "    # replaceing gamma value by optimal_param\n",
    "    # grabing C by trial and error\n",
    "    mod = SVC(C =80, gamma= 'scale', probability=True)\n",
    "    mod.fit(X=X[train, :], y=Y[train])\n",
    "    \n",
    "    # Predict and collect probability estimates\n",
    "    prob_estimates[test, i] = mod.predict_proba(X[test, :])[:,  1]\n",
    "\n",
    "# Calculate the mean probability estimate across iterations for each test instance\n",
    "mean_prob_estimates = np.nanmean(prob_estimates, axis=1)\n",
    "#print(mean_prob_estimates)\n",
    "fpr, tpr, thresholds = roc_curve(Y, mean_prob_estimates, pos_label=1)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb3ad1-3f67-403e-9ee4-775b67f76660",
   "metadata": {},
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867962a5-b639-4d39-882c-5a42a68e891c",
   "metadata": {},
   "source": [
    "Was this exercise is difficult or not? In either case, briefly describe why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e27250",
   "metadata": {},
   "source": [
    "One of the hardest challenge in this question was to define a costume scoring function for using one group out coss validation by 1000 iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8063056",
   "metadata": {},
   "source": [
    "Choosing the right kernel for Support Vector Machines (SVMs) can indeed be a complex task, as it heavily influences the model's performance. The Radial Basis Function (RBF) kernel is often favored for its ability to handle complex, non-linear patterns in the data, as it maps the input data into a higher-dimensional space where linear separation becomes possible. also I know RBF usually works well for classification as it comes by multiplication of infinite dimensions. However, when I switched to a linear kernel, I encountered an unexpected outcome. my Area Under the Curve (AUC) dropped to approximately 0.5. Despite the intuitive nature of linear kernels in handling high-dimensional spaces without explicit mapping to a higher dimension, this result was puzzling. I'm still contemplating why the simple operation of calculating dot products between feature vectors led to such a significant decrease in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "345378d9-436b-42d6-8444-4d0edc4b1ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6173469387755102\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([1, 2]*14)\n",
    "X = np.random.uniform(size=[len(Y), 100])\n",
    "n_iter = 1000\n",
    "ansMat = np.full((len(Y), n_iter), np.nan)\n",
    "for i in range(n_iter):\n",
    "    # Get train/test index\n",
    "    train = np.random.choice(range(len(Y)), size=int(0.5*len(Y)), replace=False, p=None)\n",
    "    if len(np.unique(Y)) == 1:\n",
    "        continue\n",
    "    test = np.array([i for i in range(len(Y)) if i not in train])\n",
    "    # train model\n",
    "    mod = SVC(kernel = 'linear',probability=False)\n",
    "    mod.fit(X=X[train, :], y=Y[train])\n",
    "    # predict and collect answer\n",
    "    ansMat[test, i] = mod.predict(X[test, :])\n",
    "ans = np.nanmean(ansMat, axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(Y, ans, pos_label=1)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5732d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
